{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a tagger for flight offer phrases\n",
    "### Like this one: \"¡CDMX a Bogotá 🇨🇴 $4,659!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                   label\n",
      "0                                                           ¡CUN a Ámsterdam $8,960! Sin escala en EE.UU\n",
      "5                              ¡GDL a Los Ángeles $3,055! Directos (Agrega 3 noches de hotel por $3,350)\n",
      "10                                      ¡CUN a Puerto Rico $3,296! (Agrega 3 noches de hotel por $2,778)\n",
      "15                    ¡LA a Seúl, regresa desde Tokio 🇯🇵 $8,607! (Por $3,147 agrega 11 noches de hostal)\n",
      "20                                           ¡CDMX a Chile $8,938! (Agrega 9 noches de hotel por $5,933)\n",
      "25                                                               ¡CUN a Holanda $8,885! Sin escala EE.UU\n",
      "30                                              ¡Todo México a París, regresa desde Amsterdam – $11,770!\n",
      "35                  ¡CDMX a Vietnam $10,244! Sin escala en EE.UU (Agrega 15 noches de hostal por $2,082)\n",
      "40                                     ¡CDMX a Europa en Semana Santa $14,984! (París + Ibiza + Venecia)\n",
      "45              ¡CDMX a Phuket, Tailandia – $12,413! (Por $3,028 agrega 5 noches de hotel con desayunos)\n",
      "50                                                                       ¡CUN a Bélgica $9,430! Directos\n",
      "55                        ¡Todo México a Madrid 🇪🇸 $10,733! (Por $4,492 agrega 9 noches de departamento)\n",
      "60                                      ¡CDMX a Noruega $10,061! (Y agrega 9 noches de hotel por $7,890!\n",
      "65                                           ¡CDMX a NYC – $3,676! (Por $4,140 agrega 4 noches de hotel)\n",
      "70                                                                     ¡NYC a Bergen, Noruega 🇳🇴 $3,920!\n",
      "75                                         ¡LA a Bangkok 🇹🇭$8,442! (Por $2,170 agrega 6 noches de Hotel)\n",
      "80                                 ¡CDMX a Bogotá $4,865! Directos (Y por $836 agrega 4 noches de hotel)\n",
      "85                                       ¡CDMX a Guatemala $3,081! (Y por $946 agrega 3 noches de hotel)\n",
      "90             ¡Todo México a París, regresa desde Roma – $12,440! (Por $4,407 agrega 7 noches de Hotel)\n",
      "95   ¡Todo México a Pisa, Toscana Italia $12,915! Sin escala EE.UU (Y por $3,975 agrega 13 noches hotel)\n",
      "100                                                                     ¡CDMX a Islas Galápagos $10,289!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset:\n",
    "vuelos = pd.read_csv('data/vuelos.csv', index_col=0)\n",
    "with pd.option_context('max_colwidth', 800):\n",
    "    print(vuelos.loc[:100:5][['label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the offers follow a simple pattern: *Destination - Origin - Price - Extras*, while extracting this may seem easy for a regular expression, it is not (see this notebook for reference). \n",
    "\n",
    "The idea is to create a tagger that will be able to extract this information, however, one first tag is to identify the information that we want to extract. Following the pattern described above: \n",
    "\n",
    " - **DST**: Destination \n",
    " - **ORI**: Origin \n",
    " - **PRC**: Price \n",
    " - **EXT**: Extras\n",
    " \n",
    "| Text \t| DST \t| ORI \t| PRC \t| OTH \t|\n",
    "|------\t|-----\t|-----\t|-----\t|-----\t|\n",
    "| ¡CUN a Holanda \\$8,885! Sin escala EE.UU | CUN | Holanda | 8,885 | Sin escala EE.UU |   \n",
    "| ¡CDMX a Noruega <span>$</span>10,061! (Y agrega 9 noches de hotel por \\$7,890!) | CDMX | Noruega | 10,061 | Y agrega 9 noches de hotel por \\$7,890!| \n",
    "| ¡Todo México a Pisa, Toscana Italia \\$12,915! Sin escala EE.UU (Y por \\$3,975 agrega 13 noches hotel) | México | Pisa, Toscana Italia | 12,915 | Sin escala EE.UU (Y por \\$3,975 agrega 13 noches hotel) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and POS-tag the dataset \n",
    "We need to generate a *csv* file that we can tag (manually 😨) that consists of:\n",
    "```\n",
    "token1    POS tag    Label\n",
    "token2    POS tag    Label\n",
    "token3    POS tag    Label\n",
    "```\n",
    "\n",
    "Where `Label` will be one of DST, ORI, PRC, OTH and NA and will be manually assigned (again: 😨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pepe', 'np00000'), ('Pecas', 'np00000'), ('pica', 'aq0000'), ('papas', 'nc0p000'), ('con', 'sp000'), ('un', 'di0000'), ('pico,', 'nc0s000'), ('con', 'sp000'), ('un', 'di0000'), ('pico', 'nc0s000'), ('pica', 'aq0000'), ('papas', 'nc0p000'), ('Pepe', 'np00000'), ('Pecas.', 'np00000')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "\n",
    "spanish_postagger = StanfordPOSTagger('/Users/antonioferegrino/stanford_nlp/'\n",
    "                                      'stanford-postagger-full-2018-02-27/models/spanish-distsim.tagger', \n",
    "                                      '/Users/antonioferegrino/stanford_nlp/'\n",
    "                                      'stanford-postagger-full-2018-02-27/stanford-postagger.jar')\n",
    "\n",
    "print(spanish_postagger.tag('Pepe Pecas pica papas con un pico, con un pico pica papas Pepe Pecas.'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡LA a Bangkok 🇹🇭$8,442! (Por $2,170 agrega 6 noches de Hotel)\n",
      "\n",
      "[('¡', 0), ('LA', 1), ('a', 4), ('Bangkok', 6), ('🇹🇭', 14), ('$', 16), ('8,442', 17), ('!', 22), ('(', 24), ('Por', 25), ('$', 16), ('2,170', 30), ('agrega', 36), ('6', 43), ('noches', 45), ('de', 52), ('Hotel', 55), (')', 60)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknz = TweetTokenizer()\n",
    "\n",
    "transforms = {\n",
    "    'LA': ['Los', 'Angeles']\n",
    "}\n",
    "\n",
    "def index_emoji_tokenize(string, return_flags=False):\n",
    "    i = 0\n",
    "    flag = ''\n",
    "    ix = 0\n",
    "    for t in tknz.tokenize(string):\n",
    "        ix = string.find(t, ix)\n",
    "        if len(t) == 1 and ord(t) >= 127462: # this is the code for 🇦\n",
    "            if not return_flags: continue\n",
    "            if flag:\n",
    "                yield flag + t, ix - 1\n",
    "                flag = ''\n",
    "            else:\n",
    "                flag = t\n",
    "        else:\n",
    "            yield t, ix\n",
    "        ix=+1\n",
    "        \n",
    "\n",
    "label = vuelos.iloc[75]['label']\n",
    "print(label)\n",
    "print()\n",
    "tokens = list(index_emoji_tokenize(label, return_flags=True))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('¡', 'faa'), ('LA', 'pp000000'), ('a', 'sp000'), ('Bangkok', 'np00000'), ('🇹🇭', 'dn0000'), ('$', 'zm'), ('8,442', 'dn0000'), ('!', 'fat'), ('(', 'np00000'), ('Por', 'sp000'), ('$', 'nc0p000'), ('2,170', 'dn0000'), ('agrega', 'vmip000'), ('6', 'dn0000'), ('noches', 'nc0p000'), ('de', 'sp000'), ('Hotel', 'np00000'), (')', 'word')]\n"
     ]
    }
   ],
   "source": [
    "simply_tokens = [ l[0] for l in tokens ]\n",
    "print(spanish_postagger.tag(simply_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(label, debug=False):\n",
    "    tokens = list(index_emoji_tokenize(label, True))\n",
    "    if debug:\n",
    "        print('Tokens', len(tokens))\n",
    "    only_tokens = [l[0] for l in tokens]\n",
    "    if debug:\n",
    "        print('Only tokens', len(only_tokens))\n",
    "    positions = [l[1] for l in tokens]\n",
    "    if debug:\n",
    "        print('Positions', len(positions))\n",
    "    tagged = spanish_postagger.tag(only_tokens)\n",
    "    if debug:\n",
    "        print('Tagged', len(tagged))\n",
    "    tags =  [l[1] for l in tagged]\n",
    "    if debug:\n",
    "        print('Tags', len(tags))\n",
    "    lengths =  [len(l) for l in only_tokens]\n",
    "    if debug:\n",
    "        print('Lengths', len(lengths))\n",
    "    n_tokens =  [len(only_tokens) for l in only_tokens]\n",
    "    if debug:\n",
    "        print('N tokens', len(n_tokens))\n",
    "    uppercase = [all([l.isupper() for l in token]) for token in only_tokens]\n",
    "    return only_tokens, positions, tags, lengths, uppercase, n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2619/2619 [1:21:32<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "# This takes quite a while\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open('data/i__training_data.csv', 'w') as w:\n",
    "    writer = csv.writer(w)\n",
    "    for i, vuelo in tqdm(list(vuelos.iterrows())):\n",
    "        result = process_label(vuelo['label'])\n",
    "        for row in zip(*result):\n",
    "            writer.writerow(( i, len(vuelo['label']) ) + row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 40969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>offer_len</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_len</th>\n",
       "      <th>all_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">44</th>\n",
       "      <th>¡</th>\n",
       "      <td>0</td>\n",
       "      <td>faa</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUN</th>\n",
       "      <td>1</td>\n",
       "      <td>np00000</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>5</td>\n",
       "      <td>sp000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ámsterdam</th>\n",
       "      <td>7</td>\n",
       "      <td>np00000</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>17</td>\n",
       "      <td>zm</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sentence_id offer_len  token    pos  token_len all_upper\n",
       "0 44 ¡                    0       faa      1  False         11         n\n",
       "     CUN                  1   np00000      3   True         11         o\n",
       "     a                    5     sp000      1  False         11         s\n",
       "     Ámsterdam            7   np00000      9  False         11         d\n",
       "     $                   17        zm      1  False         11         n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('data/i__training_data.csv', header=None,\n",
    "                            names=['sentence_id', 'offer_len', 'token', 'pos', 'token_len', 'all_upper'])\n",
    "print(f'Length {len(training_data)}')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens 22\n",
      "Only tokens 22\n",
      "Positions 22\n",
      "Tagged 22\n",
      "Tags 22\n",
      "Lengths 22\n",
      "N tokens 22\n"
     ]
    }
   ],
   "source": [
    "values = process_label(vuelos.iloc[3]['label'], debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
